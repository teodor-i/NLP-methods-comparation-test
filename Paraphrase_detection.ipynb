{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "Paraphrase detection.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqYhYroIBDz_"
      },
      "source": [
        "# NLP methods in Paraphrase detection\n",
        "\n",
        "Тестовый ноутбук, чтобы сравнить unsupervices и supervised подходы к вычеслению схожести текстов\n",
        "Для решении задачи используем русскоязычный корпус ParaPhraser.\n",
        "* Часть 1: Unsupervised methods \n",
        "* Часть 2: Supervised methods \n",
        "\n",
        "\n",
        "Изучим:\n",
        "\n",
        "Embeddings\n",
        "    - word2vec \n",
        "    - word2vec with weights\n",
        "    - doc2vec \n",
        "    - ELMo \n",
        "    \n",
        "Models\n",
        "    - LogReg\n",
        "    - SVM\n",
        "    - RandomForest\n",
        "    - GradientBoosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "_cXK6kblBD0H"
      },
      "source": [
        "#### Загрузка библиотек и данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T11:11:38.405967Z",
          "start_time": "2018-11-09T11:11:31.830360Z"
        },
        "hidden": true,
        "id": "rjIugX9GBD0H"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from gensim.models import word2vec\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings('ignore')\n",
        "random.seed(42)\n",
        "import pymorphy2\n",
        "\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from gensim.models.wrappers import FastText\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T11:11:38.488661Z",
          "start_time": "2018-11-09T11:11:38.408775Z"
        },
        "hidden": true,
        "id": "Rv393uEnBD0I"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import SVC  \n",
        "#from xgboost import XGBClassifier\n",
        "from sklearn.metrics import make_scorer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-07T17:44:29.733923Z",
          "start_time": "2018-11-07T17:44:29.664786Z"
        },
        "hidden": true,
        "id": "51QeclJJBD0I"
      },
      "source": [
        "data = pd.read_csv('data_hw2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "xiOmJfhdBD0I"
      },
      "source": [
        "*Отнесем все объекты класса 0 к классу 1:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-07T17:44:30.846420Z",
          "start_time": "2018-11-07T17:44:30.835064Z"
        },
        "hidden": true,
        "id": "wOSaqWrcBD0J"
      },
      "source": [
        "data['class_bin'] = data['class'].apply(lambda x: 1 if x != -1 else -1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XQSVn-UBD0J"
      },
      "source": [
        "# 1. Unsupervised \n",
        "\n",
        "*Краткое описание:*\n",
        "* *с помощью предобученной модели FastText получаем эмбеддинги для данных*\n",
        "* *подбираем значение порога на обучаемой выборке*\n",
        "* *строим предсказания для тестовой выборки, измеряем качество*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "9-5frfXTBD0J"
      },
      "source": [
        "#### 1.1 Предобработка текста и разделение данных на обучающую и тестовую выборку [unsupervised]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "7L4O2-oEBD0K"
      },
      "source": [
        "*Лемматизация с помощью Pymorphy, союзы и предлоги удалены.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T11:11:57.037392Z",
          "start_time": "2018-11-09T11:11:57.031491Z"
        },
        "hidden": true,
        "id": "stV_SSmhBD0K"
      },
      "source": [
        "def simple_processing(texts):\n",
        "    prog = re.compile(\"[А-Яа-яёA-Za-z]+\")\n",
        "    morph = pymorphy2.MorphAnalyzer()\n",
        "    make_list = []\n",
        "    for text in tqdm(texts):\n",
        "        line = prog.findall(str(text).lower()) \n",
        "        words = [morph.parse(token)[0].normal_form for token in line\n",
        "                if not morph.parse(token)[0].tag.POS in ['PREP', 'CONJ'] ]\n",
        "        make_list.append(words)\n",
        "    return make_list\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-07T14:19:31.630048Z",
          "start_time": "2018-11-07T14:18:19.572649Z"
        },
        "hidden": true,
        "id": "GNqRry78BD0K"
      },
      "source": [
        "data['text_1'] = simple_processing(data['text_1'])\n",
        "data['text_2'] = simple_processing(data['text_2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-07T14:19:31.647737Z",
          "start_time": "2018-11-07T14:19:31.633355Z"
        },
        "hidden": true,
        "id": "Xkdie-oVBD0K"
      },
      "source": [
        "data_train, data_test = train_test_split(data, test_size = 0.25, random_state = 666)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "eeQgIE7IBD0L"
      },
      "source": [
        "#### 1.2 Необходимые функции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-07T15:16:19.177651Z",
          "start_time": "2018-11-07T15:16:19.158174Z"
        },
        "collapsed": true,
        "hidden": true,
        "id": "WusW5CslBD0L"
      },
      "source": [
        "def wmd(doc_1, doc_2, model):\n",
        "    '''\n",
        "    Word Mover's Distance between two documents.\n",
        "  \n",
        "    Parameters\n",
        "    ----------\n",
        "    doc_1, doc_2: list of tokens (words)\n",
        "        Two documents\n",
        "    model: \n",
        "        Model produced word emdeddings\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        Computed Word Mover's Distance based on trained model \n",
        "    '''\n",
        "    \n",
        "    return model.wmdistance(doc_1, doc_2)\n",
        "\n",
        "\n",
        "def prediction(text_1, text_2, threshold, model):\n",
        "    '''\n",
        "    Create predictions according to Word Mover's Distance between two documents (texts)\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    text_1, text_2: list of lists\n",
        "        Two lists of documents (texts)\n",
        "    threshold: float\n",
        "        Threshold to define label for pair of documents\n",
        "    model:\n",
        "        Model produced word embeddings\n",
        "    \n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    list of floats\n",
        "        Predictions for these lists of documents (texts)\n",
        "    '''\n",
        "    \n",
        "    y_pred = []\n",
        "    if len(text_1) != len(text_2):\n",
        "        print('Arrays must be same size')\n",
        "    else:\n",
        "        for i in range(len(text_1)):\n",
        "            if wmd(text_1[i], text_2[i], model) < threshold:\n",
        "                y_pred.append(1)\n",
        "            else:\n",
        "                y_pred.append(-1)\n",
        "        return y_pred\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh5TwO3ZBD0L"
      },
      "source": [
        "#### 1.3 Загрузка модели эмбеддингов, подбор оптимального порога"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-07T15:07:55.980819Z",
          "start_time": "2018-11-07T14:54:24.774401Z"
        },
        "collapsed": true,
        "id": "RPtHr6ngBD0L"
      },
      "source": [
        "# загружаем предобученную модель эмбеддингов\n",
        "\n",
        "model = FastText.load_fasttext_format('cc.ru.300.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-07T15:21:12.424866Z",
          "start_time": "2018-11-07T15:19:05.561064Z"
        },
        "collapsed": true,
        "id": "wlUbZEuVBD0M"
      },
      "source": [
        "thresholds = np.arange(0.6, 0.9, 0.02) \n",
        "accuracy, f1_macro = [], []\n",
        "y = data_train['class_bin']\n",
        "for t in thresholds:\n",
        "    y_pred = prediction(data_train['text_1'].values, data_train['text_2'].values, t, model)\n",
        "    accuracy.append(accuracy_score(y, y_pred))\n",
        "    f1_macro.append(f1_score(y, y_pred, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-07T15:28:23.252345Z",
          "start_time": "2018-11-07T15:28:22.904607Z"
        },
        "id": "ArPl9sdSBD0M",
        "outputId": "cb5d5d39-66d8-4fb5-a230-7f76a73c5307"
      },
      "source": [
        "fig = plt.figure(figsize=(15, 7))\n",
        "plt.title('F1-score and accuracy according to thresholds')\n",
        "plt.plot(thresholds, accuracy)\n",
        "plt.plot(thresholds, f1_macro)\n",
        "plt.grid(0)\n",
        "plt.legend(('accuracy', 'micro'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x1bffc41a20>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "vUu07tyIBD0N"
      },
      "source": [
        "#### 1.4 Создание предсказаний для тестовой выборки, оценка качества "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "yXGhLMUoBD0N"
      },
      "source": [
        "*Был подобран следующий порог:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-07T15:35:09.937277Z",
          "start_time": "2018-11-07T15:35:07.402813Z"
        },
        "collapsed": true,
        "hidden": true,
        "id": "h5q5QKU1BD0N"
      },
      "source": [
        "y_pred = prediction(data_test['text_1'].values, data_test['text_2'].values, 0.725, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-07T15:35:09.953617Z",
          "start_time": "2018-11-07T15:35:09.939853Z"
        },
        "hidden": true,
        "id": "NhcLCWmmBD0N",
        "outputId": "84584e2d-9373-48b3-b448-01b5fcd5765d"
      },
      "source": [
        "print('Test set accuracy score: %.3f' % accuracy_score(data_test['class_bin'], y_pred))\n",
        "print('Test set f1_macro score: %.3f' % f1_score(data_test['class_bin'], y_pred, average='macro')) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score: 0.7360265633646929\n",
            "f1_macro score: 0.6956736345388971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkye4wpaBD0O"
      },
      "source": [
        "# 2. Supervised I: сведение задачи к бинарной классификации\n",
        "\n",
        "*Краткое описание:*\n",
        "* векторизуем тексты несколькими способами\n",
        "* выбираем модели, подбираем гиперпараметры\n",
        "* оцениваем качество \n",
        "\n",
        "*Используемые модели эмбеддингов:*\n",
        "\n",
        " - word2vec \n",
        " - word2vec with weights\n",
        " - doc2vec \n",
        " - ELMo\n",
        " \n",
        "*Модели классификации:*\n",
        "\n",
        " - LogisticRegression\n",
        " - SVM\n",
        " - RandomForest\n",
        " - GradientBoosting\n",
        " \n",
        " \n",
        " ! Для Word2Vec нужна отдельная функция лемматизации word -> lemma_tag\n",
        "Можно сделать тремя способами:\n",
        "\n",
        "- udpipe (но плохая лемматизация)\n",
        "- mystem + смена тэгсета (но очень долго)\n",
        "- pymorphy + смена тэгсета (но очень много чего теряем)\n",
        "\n",
        " ! Для Doc2vec обычная лемматизация из unsupervised части"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBYFKruhBD0O"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC1SB1IQBD0O"
      },
      "source": [
        "##### Необходимые функции:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T13:18:48.070426Z",
          "start_time": "2018-11-09T13:18:48.063253Z"
        },
        "id": "-VdLPJQXBD0P"
      },
      "source": [
        "class score_report(object):\n",
        "    '''\n",
        "    Class for creating DataFrame with results\n",
        "    '''\n",
        "    \n",
        "    def __init__(self):\n",
        "        '''\n",
        "        Constructor of class\n",
        "        '''\n",
        "        e = ['Word2Vec', 'Weighted_Word2Vec', 'Doc2Vec', 'Fasttext', 'Weighted_Fasttext']\n",
        "        m = ['logreg_acc', 'logreg_f1', 'svm_acc', 'svm_f1', \n",
        "             'boost_acc', 'boost_f1', 'forest_acc', 'forest_f1']\n",
        "        self.data = pd.DataFrame(index = e, columns = m)\n",
        "        \n",
        "    def add(self, score, clf, metric, embedding):\n",
        "        '''\n",
        "        Add score with corresponding name of model, metric and embedding model\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        score: float\n",
        "            Score of the model\n",
        "        clf: str\n",
        "            Name of model, for example: 'logreg'\n",
        "        metric: str\n",
        "            One of these metrics: 'acc' or 'f1' correspond to 'accuracy' and 'f1 macro score' respectfully\n",
        "        embedding:\n",
        "            Name of embedding model, for example: 'Word2Vec'\n",
        "        \n",
        "        '''\n",
        "        \n",
        "        model = clf + '_' + metric\n",
        "        results = self.data\n",
        "        results.loc[embedding][model] = score\n",
        "    \n",
        "    def show(self):\n",
        "        '''\n",
        "        Show DataFrame with results\n",
        "        '''\n",
        "        return self.data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T13:18:48.577094Z",
          "start_time": "2018-11-09T13:18:48.569889Z"
        },
        "id": "0dsRRG5kBD0P"
      },
      "source": [
        "results = score_report()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukyQC1fXBD0P"
      },
      "source": [
        "### 2.1 Word2Vec: усредненный & усредненный с весами"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "MhO9ZHZVBD0P"
      },
      "source": [
        "#### Предобработка текста, разделение данных на обучающую и тестовую выборку [supervised] \n",
        "Для использования предобученной модель word2vec с RusVectores, то необходимо, чтобы слова в текстах имели вид **lemma + POS_tag** (корпус, на котором обучена модель, был обработан с помощью udpipe). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "cH-vnRnLBD0Q"
      },
      "source": [
        "##### Функция для предобработки с udpipe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "2egOtOTiBD0Q",
        "outputId": "85156a67-8781-4212-cc39-713b51a51f68"
      },
      "source": [
        "!pip install ufal.udpipe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ufal.udpipe in ./anaconda3/envs/fastai/lib/python3.6/site-packages\n",
            "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
            "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "xWnT7JXkBD0Q",
        "outputId": "d129408e-653d-4eff-a0ed-285ef5dc73a6"
      },
      "source": [
        "!pip install conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: conllu in ./anaconda3/envs/fastai/lib/python3.6/site-packages\n",
            "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
            "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-07T20:08:12.345609Z",
          "start_time": "2018-11-07T20:07:35.712271Z"
        },
        "hidden": true,
        "id": "OZYEg1ILBD0R"
      },
      "source": [
        "from ufal.udpipe import Model, Pipeline\n",
        "from conllu import parse\n",
        "\n",
        "model = Model.load(\"russian-ud-2.0-170801.udpipe\")\n",
        "pipeline = Pipeline(model, 'generic_tokenizer', '', '', '')\n",
        "\n",
        "\n",
        "def udpipe_processing(lst):\n",
        "    pattern = re.compile(\"[А-Яа-я]+|[A-Za-z]+\") \n",
        "    make_list = []\n",
        "    for text in lst:\n",
        "        words = ' '.join(pattern.findall(text))\n",
        "        parsed = pipeline.process(words)\n",
        "        sentence = parse(parsed)\n",
        "        sents = []\n",
        "        for i in range(len(sentence[0])):\n",
        "            sents.append(sentence[0][i]['lemma'].lower() + '_' + sentence[0][i]['upostag']) \n",
        "            #конкатенируем лемму и тэг\n",
        "        make_list.append(sents)\n",
        "        \n",
        "    return make_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "w5et98paBD0R"
      },
      "source": [
        "##### Функция для предобработки с mystem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "a2ffpnOOBD0R"
      },
      "source": [
        "*! Не забыть написать откуда взяли функцию* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "zxoZxBvOBD0R",
        "outputId": "d04eecc0-5c5e-49d9-8a13-f16060252859"
      },
      "source": [
        "!pip install pymystem3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymystem3\n",
            "  Downloading https://files.pythonhosted.org/packages/00/8c/98b43c5822620458704e187a1666616c1e21a846ede8ffda493aabe11207/pymystem3-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: requests in ./anaconda3/envs/fastai/lib/python3.6/site-packages (from pymystem3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./anaconda3/envs/fastai/lib/python3.6/site-packages (from requests->pymystem3)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in ./anaconda3/envs/fastai/lib/python3.6/site-packages (from requests->pymystem3)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in ./anaconda3/envs/fastai/lib/python3.6/site-packages (from requests->pymystem3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/fastai/lib/python3.6/site-packages (from requests->pymystem3)\n",
            "Installing collected packages: pymystem3\n",
            "Successfully installed pymystem3-0.2.0\n",
            "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
            "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "g1oBtaq8BD0S"
      },
      "source": [
        "from pymystem3 import Mystem\n",
        "\n",
        "mapping = {'COM': 'ADJ',  #mystem : udpipe\n",
        "           'APRO': 'DET',\n",
        "           'PART': 'PART',\n",
        "           'PR': 'ADP',\n",
        "           'ADV': 'ADV',\n",
        "           'INTJ': 'INTJ',\n",
        "           'S': 'NOUN',\n",
        "           'V': 'VERB',\n",
        "           'CONJ': 'SCONJ',\n",
        "           'UNKN': 'X',\n",
        "           'ANUM': 'ADJ',\n",
        "           'NUM': 'NUM',\n",
        "           'NONLEX': 'X',\n",
        "           'SPRO': 'PRON',\n",
        "           'ADVPRO': 'ADV',\n",
        "           'A': 'ADJ'}\n",
        "\n",
        "def tag_mystem(doc):  \n",
        "    m = Mystem()\n",
        "    processed = m.analyze(doc)\n",
        "    tagged = []\n",
        "    for w in processed:\n",
        "        try:\n",
        "            lemma = w[\"analysis\"][0][\"lex\"].lower().strip()\n",
        "            pos = w[\"analysis\"][0][\"gr\"].split(',')[0]\n",
        "            pos = pos.split('=')[0].strip()\n",
        "            if pos in mapping:\n",
        "                tagged.append(lemma + '_' + mapping[pos]) # здесь мы конвертируем тэги\n",
        "            else:\n",
        "                tagged.append(lemma + '_X') # на случай, если попадется тэг, которого нет в маппинге\n",
        "        except KeyError:\n",
        "            continue # я здесь пропускаю знаки препинания, но вы можете поступить по-другому\n",
        "    return tagged\n",
        "\n",
        "def mystem_processing(lst):\n",
        "    res = []\n",
        "    for i in tqdm(range(len(lst))):\n",
        "        res.append(tag_mystem(lst[i]))\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "Z-wUDH_qBD0S"
      },
      "source": [
        "#####  Функция для обработки с помощью pymorhy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "-SOHRXnyBD0S"
      },
      "source": [
        "# словарь для замены POS-тэгов \n",
        "tags = {'ADJF':'ADJ', # pymorphy2 : udpipe \n",
        "'ADJS' : 'ADJ', \n",
        "'ADVB' : 'ADV', \n",
        "'COMP' : 'ADV', \n",
        "'GRND' : 'VERB', \n",
        "'INFN' : 'VERB', \n",
        "'NOUN' : 'NOUN', \n",
        "'PRED' : 'ADV', \n",
        "'PRTF' : 'ADJ', \n",
        "'PRTS' : 'VERB', \n",
        "'VERB' : 'VERB'}\n",
        "\n",
        "\n",
        "def processing_with_tags(texts):\n",
        "    prog = re.compile(\"[А-Яа-яёA-Za-z]+\")\n",
        "    morph = pymorphy2.MorphAnalyzer()\n",
        "    make_list = []\n",
        "    for text in tqdm(texts):\n",
        "        line = prog.findall(str(text).lower())\n",
        "        words = [morph.parse(token)[0].normal_form + '_' + tags[morph.parse(token)[0].tag.POS] for token in line\n",
        "                if morph.parse(token)[0].tag.POS in tags.keys()]\n",
        "        make_list.append(words)\n",
        "    return make_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "ChKMLqUbBD0T"
      },
      "source": [
        "##### Лемматизируем данные, делим на обучающую и тестовую выборку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T12:55:47.685809Z",
          "start_time": "2018-11-08T12:54:31.701348Z"
        },
        "hidden": true,
        "id": "y4HmkDUxBD0T"
      },
      "source": [
        "data['text_1'] = udpipe_processing(data['text_1'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "iDW-ZgT8BD0T"
      },
      "source": [
        "data['text_2'] = udpipe_processing(data['text_2'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "feHDg6xYBD0T"
      },
      "source": [
        "#pd.to_pickle(data, 'data_after_udpipe.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "pDQQHz7YBD0T"
      },
      "source": [
        "data = pd.read_pickle('data_after_udpipe.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T12:55:49.574432Z",
          "start_time": "2018-11-08T12:55:49.509743Z"
        },
        "hidden": true,
        "id": "giciWpWBBD0U"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data[['text_1', 'text_2']], data['class_bin'], test_size = 0.25,\n",
        "                                                    random_state = 666)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfwYHPjGBD0U",
        "outputId": "72fdb61a-552e-4d85-c372-744db605dfe1"
      },
      "source": [
        "X_train['text_1'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['полицейский_NOUN',\n",
              " 'разрешат_VERB',\n",
              " 'стрелять_VERB',\n",
              " 'на_ADP',\n",
              " 'поражение_NOUN',\n",
              " 'по_ADP',\n",
              " 'гражданин_NOUN',\n",
              " 'с_ADP',\n",
              " 'травматикой_NOUN']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "vCF5n144BD0U"
      },
      "source": [
        "#### Строим эмбеддинги: усредненный word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T14:57:04.919376Z",
          "start_time": "2018-11-08T14:53:09.630155Z"
        },
        "hidden": true,
        "id": "EZ2C1wNOBD0U"
      },
      "source": [
        "# загрузка предобученной модели\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(\"ruscorpora_upos_skipgram_300_5_2018.vec.gz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "DemqKtTtBD0U"
      },
      "source": [
        "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T11:34:41.376387Z",
          "start_time": "2018-11-08T11:34:41.346297Z"
        },
        "hidden": true,
        "id": "uy_K9QHIBD0V"
      },
      "source": [
        "class MeanEmbeddingVectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        self.dim = len(w2v.popitem()[1])\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return [np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T15:59:51.492656Z",
          "start_time": "2018-11-08T15:59:51.384312Z"
        },
        "hidden": true,
        "id": "C1MR3ZTxBD0V"
      },
      "source": [
        "mean_emb = MeanEmbeddingVectorizer(w2v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "sGMPbgHKBD0V"
      },
      "source": [
        "X_train_text_2 = mean_emb.transform(X_train.text_2.values)\n",
        "X_test_text_2 = mean_emb.transform(X_test.text_2.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "gOyojgW2BD0V"
      },
      "source": [
        "X_train_text_1 = mean_emb.transform(X_train.text_1.values)\n",
        "X_test_text_1 = mean_emb.transform(X_test.text_1.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "8E_YbNucBD0W"
      },
      "source": [
        "X_train = [np.concatenate((X_train_text_1[i], X_train_text_2[i])) for i in range(len(X_train_text_1))]\n",
        "X_test = [np.concatenate((X_test_text_1[i], X_test_text_2[i])) for i in range(len(X_test_text_1))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "GpL9eyJnBD0W"
      },
      "source": [
        "#### Word2Vec + LogReg, SVM, RandomForest, GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "rQ8YGvxGBD0W",
        "outputId": "c815da3a-7666-4126-82cd-75c26fc97ace"
      },
      "source": [
        "pipe_logreg = LogisticRegression(random_state=666, n_jobs = -1)\n",
        "pipe_svm = SVC(random_state=666)\n",
        "pipe_forest = RandomForestClassifier(random_state=666)\n",
        "pipe_boost = GradientBoostingClassifier(random_state=666)\n",
        "\n",
        "grid_params_logreg = [{'penalty': ('l1', 'l2'),\n",
        "                   'C': [1.0, 0.5, 0.1]}] \n",
        "\n",
        "grid_params_svm = [{'kernel': ('linear', 'poly', 'rbf'),\n",
        "                   'C': [1.0, 0.5, 0.1],\n",
        "                   'degree': [3, 5]}] \n",
        "\n",
        "grid_params_forest = [{'n_estimators' : [10, 20], \n",
        "                   'criterion': ('gini', 'entropy'),\n",
        "                   'min_samples_leaf': [50, 100, 200],\n",
        "                   'max_depth': [50, 100],\n",
        "                   'min_samples_split': [50, 100]}]\n",
        "\n",
        "grid_params_boost = [{'loss': ('deviance', 'exponential'), \n",
        "                    'min_samples_leaf': [50, 100], \n",
        "                    'subsample' : [0.5, 0.7, 1.0], \n",
        "                    'n_estimators' : [100, 200]}]\n",
        "\n",
        "\n",
        "models = {'logreg' : [pipe_logreg, grid_params_logreg],\n",
        "          'svm' : [pipe_svm, grid_params_svm], \n",
        "          'forest': [pipe_forest, grid_params_forest],\n",
        "          'boost' : [pipe_boost, grid_params_boost]}\n",
        "\n",
        "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
        "          'f1_score_macro' : make_scorer(f1_score, average = 'macro')}\n",
        "\n",
        "\n",
        "best_acc = 0.0\n",
        "best_f1 = 0.0\n",
        "best_clf_acc = ''\n",
        "best_clf_f1 = ''\n",
        "\n",
        "\n",
        "for clf in models.keys():\n",
        "    print('\\nEstimator: %s' % models[clf])\n",
        "    grid_cv = GridSearchCV(estimator = models[clf][0], param_grid = models[clf][1][0], n_jobs = -1, \n",
        "                           scoring = scoring, refit = 'f1_score_macro')\n",
        "    grid_cv.fit(X_train, y_train)\n",
        "    print('Best params: %s' % grid_cv.best_params_)\n",
        "    print('Best training accuracy: %.3f' % grid_cv.best_score_)\n",
        "    y_pred = grid_cv.predict(X_test)\n",
        "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
        "    print('Test set f1_score (macro) for best params: %.3f ' % f1_score(y_test, y_pred, average='macro'))\n",
        "    results.add(accuracy_score(y_test, y_pred), clf, 'acc', 'Word2Vec')\n",
        "    results.add(f1_score(y_test, y_pred, average='macro'), clf, 'f1', 'Word2Vec')\n",
        "    if accuracy_score(y_test, y_pred) > best_acc:\n",
        "        best_acc = accuracy_score(y_test, y_pred)\n",
        "        best_clf_acc = str(grid_cv.best_estimator_)\n",
        "        \n",
        "    if f1_score(y_test, y_pred, average='macro') > best_f1:\n",
        "        best_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "        best_clf_f1 = str(grid_cv.best_estimator_)\n",
        "        \n",
        "print('\\nClassifier with best test set accuracy: %s' % best_clf_acc)\n",
        "print('\\nClassifier with best test set f1 macro score: %s' % best_clf_f1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Estimator: [LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
            "          penalty='l2', random_state=666, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False), [{'penalty': ('l1', 'l2'), 'C': [1.0, 0.5, 0.1]}]]\n",
            "Best params: {'C': 1.0, 'penalty': 'l2'}\n",
            "Best training accuracy: 0.537\n",
            "Test set accuracy score for best params: 0.679 \n",
            "Test set f1_score (macro) for best params: 0.567 \n",
            "\n",
            "Estimator: [SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
            "  max_iter=-1, probability=False, random_state=666, shrinking=True,\n",
            "  tol=0.001, verbose=False), [{'kernel': ('linear', 'poly', 'rbf'), 'C': [1.0, 0.5, 0.1], 'degree': [3, 5]}]]\n",
            "Best params: {'C': 1.0, 'degree': 3, 'kernel': 'linear'}\n",
            "Best training accuracy: 0.503\n",
            "Test set accuracy score for best params: 0.680 \n",
            "Test set f1_score (macro) for best params: 0.517 \n",
            "\n",
            "Estimator: [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
            "            oob_score=False, random_state=666, verbose=0, warm_start=False), [{'n_estimators': [10, 20], 'criterion': ('gini', 'entropy'), 'min_samples_leaf': [50, 100, 200], 'max_depth': [50, 100], 'min_samples_split': [50, 100]}]]\n",
            "Best params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 50, 'min_samples_split': 50, 'n_estimators': 10}\n",
            "Best training accuracy: 0.496\n",
            "Test set accuracy score for best params: 0.667 \n",
            "Test set f1_score (macro) for best params: 0.490 \n",
            "\n",
            "Estimator: [GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=1, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "              presort='auto', random_state=666, subsample=1.0, verbose=0,\n",
            "              warm_start=False), [{'loss': ('deviance', 'exponential'), 'min_samples_leaf': [50, 100], 'subsample': [0.5, 0.7, 1.0], 'n_estimators': [100, 200]}]]\n",
            "Best params: {'loss': 'deviance', 'min_samples_leaf': 100, 'n_estimators': 200, 'subsample': 0.7}\n",
            "Best training accuracy: 0.681\n",
            "Test set accuracy score for best params: 0.728 \n",
            "Test set f1_score (macro) for best params: 0.668 \n",
            "\n",
            "Classifier with best test set accuracy: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=100, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
            "              presort='auto', random_state=666, subsample=0.7, verbose=0,\n",
            "              warm_start=False)\n",
            "\n",
            "Classifier with best test set f1 macro score: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=100, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
            "              presort='auto', random_state=666, subsample=0.7, verbose=0,\n",
            "              warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNkDsi5DBD0X"
      },
      "source": [
        "#### Строим эмбеддинги: усредненный  word2vec с весами"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nrTCpFnBD0X"
      },
      "source": [
        "data = pd.read_pickle('data_after_udpipe.pkl')\n",
        "data['class_bin'] = data['class'].apply(lambda x: 1 if x != -1 else -1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbGybjvbBD0X"
      },
      "source": [
        "data['text_1_con'] = [' '.join(text) for text in data['text_1']]\n",
        "data['text_2_con'] = [' '.join(text) for text in data['text_2']]\n",
        "corpus = pd.concat([data['text_1_con'], data['text_2_con']]).unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7va5VJahBD0X"
      },
      "source": [
        "corpus = pd.concat([data['text_1_con'], data['text_2_con']]).unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG1cCRznBD0X"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data[['text_1', 'text_2']], data['class_bin'], test_size = 0.25,\n",
        "                                                    random_state = 666)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKpUHBTrBD0Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVHx25DBD0Y"
      },
      "source": [
        "class TfidfEmbeddingVectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        self.word2weight = None\n",
        "        self.dim = len(w2v.popitem()[1])\n",
        "\n",
        "    def fit(self, X):\n",
        "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
        "        tfidf.fit(X)\n",
        "        max_idf = max(tfidf.idf_)\n",
        "        self.word2weight = defaultdict(\n",
        "            lambda: max_idf,\n",
        "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
        "                         for w in words if w in self.word2vec] or\n",
        "                        [np.zeros(self.dim)], axis=0)\n",
        "                for words in X])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_1O-ENuBD0Y"
      },
      "source": [
        "w2v = dict(zip(model.wv.index2word, model.wv.syn0)) #  модель эмбеддингов всё та же"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idEGMgsVBD0Y"
      },
      "source": [
        "tf_emb = TfidfEmbeddingVectorizer(w2v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyJMZUqEBD0Z",
        "outputId": "58bfeb0c-08dd-402d-d515-2d3d94718ac8"
      },
      "source": [
        "tf_emb.fit(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.TfidfEmbeddingVectorizer at 0x7fb37896c7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KNir64zBD0a"
      },
      "source": [
        "X_train_text_1, X_test_text_1 = tf_emb.transform(X_train.text_1.values), tf_emb.transform(X_test.text_1.values)\n",
        "X_train_text_2, X_test_text_2  = tf_emb.transform(X_train.text_2.values), tf_emb.transform(X_test.text_2.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weLhuYJQBD0a"
      },
      "source": [
        "X_train = [np.concatenate((X_train_text_1[i], X_train_text_2[i])) for i in range(len(X_train_text_1))]\n",
        "X_test = [np.concatenate((X_test_text_1[i], X_test_text_2[i])) for i in range(len(X_test_text_1))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phYAyfrABD0a"
      },
      "source": [
        "#### Weighted Word2Vec + LogReg, SVM, RandomForest, GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DJGqrZTBD0a",
        "outputId": "dddf0c3b-aa1b-4e17-98db-63d0f9a525fb"
      },
      "source": [
        "pipe_logreg = LogisticRegression(random_state=666, n_jobs = -1)\n",
        "\n",
        "pipe_svm = SVC(random_state=666)\n",
        "\n",
        "pipe_forest = RandomForestClassifier(random_state=666)\n",
        "\n",
        "pipe_boost = GradientBoostingClassifier(random_state=666)\n",
        "\n",
        "grid_params_logreg = [{'penalty': ('l1', 'l2'),\n",
        "                   'C': [1.0, 0.5, 0.1]}] \n",
        "\n",
        "grid_params_svm = [{'kernel': ('linear', 'poly', 'rbf'),\n",
        "                   'C': [1.0, 0.5, 0.1],\n",
        "                   'degree': [3, 5]}] \n",
        "\n",
        "grid_params_forest = [{'n_estimators' : [10, 20], \n",
        "                   'criterion': ('gini', 'entropy'),\n",
        "                   'min_samples_leaf': [50, 100, 200],\n",
        "                   'max_depth': [50, 100],\n",
        "                   'min_samples_split': [50, 100]}]\n",
        "\n",
        "grid_params_boost = [{'loss': ('deviance', 'exponential'), \n",
        "                    'min_samples_leaf': [50, 100], \n",
        "                    'subsample' : [0.5, 0.7, 1.0], \n",
        "                    'n_estimators' : [100, 200]}]\n",
        "\n",
        "\n",
        "models = {'logreg' : [pipe_logreg, grid_params_logreg],\n",
        "          'svm' : [pipe_svm, grid_params_svm], \n",
        "          'forest': [pipe_forest, grid_params_forest],\n",
        "          'boost' : [pipe_boost, grid_params_boost]}\n",
        "\n",
        "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
        "          'f1_score_macro' : make_scorer(f1_score, average = 'macro')}\n",
        "\n",
        "\n",
        "best_acc = 0.0\n",
        "best_f1 = 0.0\n",
        "best_clf_acc = ''\n",
        "best_clf_f1 = ''\n",
        "\n",
        "\n",
        "for clf in models.keys():\n",
        "    print('\\nEstimator: %s' % models[clf])\n",
        "    grid_cv = GridSearchCV(estimator = models[clf][0], param_grid = models[clf][1][0], n_jobs = -1, \n",
        "                           scoring = scoring, refit = 'f1_score_macro')\n",
        "    grid_cv.fit(X_train, y_train)\n",
        "    print('Best params: %s' % grid_cv.best_params_)\n",
        "    print('Best training accuracy: %.3f' % grid_cv.best_score_)\n",
        "    y_pred = grid_cv.predict(X_test)\n",
        "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
        "    print('Test set f1_score (macro) for best params: %.3f ' % f1_score(y_test, y_pred, average='macro'))\n",
        "    results.add(accuracy_score(y_test, y_pred), clf, 'acc', 'Weighted_Word2Vec')\n",
        "    results.add(f1_score(y_test, y_pred, average='macro'), clf, 'f1', 'Weighted_Word2Vec')\n",
        "    if accuracy_score(y_test, y_pred) > best_acc:\n",
        "        best_acc = accuracy_score(y_test, y_pred)\n",
        "        best_clf_acc = str(grid_cv.best_estimator_)\n",
        "        \n",
        "    if f1_score(y_test, y_pred, average='macro') > best_f1:\n",
        "        best_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "        best_clf_f1 = str(grid_cv.best_estimator_)\n",
        "        \n",
        "print('\\nClassifier with best test set accuracy: %s' % best_clf_acc)\n",
        "print('\\nClassifier with best test set f1 macro score: %s' % best_clf_f1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Estimator: [LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
            "          penalty='l2', random_state=666, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False), [{'penalty': ('l1', 'l2'), 'C': [1.0, 0.5, 0.1]}]]\n",
            "Best params: {'C': 0.5, 'penalty': 'l2'}\n",
            "Best training accuracy: 0.592\n",
            "Test set accuracy score for best params: 0.644 \n",
            "Test set f1_score (macro) for best params: 0.580 \n",
            "\n",
            "Estimator: [SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
            "  max_iter=-1, probability=False, random_state=666, shrinking=True,\n",
            "  tol=0.001, verbose=False), [{'kernel': ('linear', 'poly', 'rbf'), 'C': [1.0, 0.5, 0.1], 'degree': [3, 5]}]]\n",
            "Best params: {'C': 0.5, 'degree': 3, 'kernel': 'linear'}\n",
            "Best training accuracy: 0.591\n",
            "Test set accuracy score for best params: 0.653 \n",
            "Test set f1_score (macro) for best params: 0.580 \n",
            "\n",
            "Estimator: [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
            "            oob_score=False, random_state=666, verbose=0, warm_start=False), [{'n_estimators': [10, 20], 'criterion': ('gini', 'entropy'), 'min_samples_leaf': [50, 100, 200], 'max_depth': [50, 100], 'min_samples_split': [50, 100]}]]\n",
            "Best params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 50, 'min_samples_split': 50, 'n_estimators': 10}\n",
            "Best training accuracy: 0.496\n",
            "Test set accuracy score for best params: 0.667 \n",
            "Test set f1_score (macro) for best params: 0.490 \n",
            "\n",
            "Estimator: [GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=1, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "              presort='auto', random_state=666, subsample=1.0, verbose=0,\n",
            "              warm_start=False), [{'loss': ('deviance', 'exponential'), 'min_samples_leaf': [50, 100], 'subsample': [0.5, 0.7, 1.0], 'n_estimators': [100, 200]}]]\n",
            "Best params: {'loss': 'deviance', 'min_samples_leaf': 100, 'n_estimators': 200, 'subsample': 0.7}\n",
            "Best training accuracy: 0.683\n",
            "Test set accuracy score for best params: 0.728 \n",
            "Test set f1_score (macro) for best params: 0.668 \n",
            "\n",
            "Classifier with best test set accuracy: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=100, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
            "              presort='auto', random_state=666, subsample=0.7, verbose=0,\n",
            "              warm_start=False)\n",
            "\n",
            "Classifier with best test set f1 macro score: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=100, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
            "              presort='auto', random_state=666, subsample=0.7, verbose=0,\n",
            "              warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzN6W_QTBD0b"
      },
      "source": [
        "### 2.2 Doc2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "hA7-eDxlBD0b"
      },
      "source": [
        "#### Лемматизируем данные, делим выборку на train и test, конкатенируем пары для создания корпуса для doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T11:11:38.562616Z",
          "start_time": "2018-11-09T11:11:38.490953Z"
        },
        "hidden": true,
        "id": "u4anh-jNBD0b"
      },
      "source": [
        "data = pd.read_csv('data_hw2.csv')\n",
        "data['class_bin'] = data['class'].apply(lambda x: 1 if x != -1 else -1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T11:12:39.089563Z",
          "start_time": "2018-11-09T11:12:02.478060Z"
        },
        "hidden": true,
        "id": "6yNCK6f6BD0c",
        "outputId": "e615803d-5b4e-46a9-9f15-da12088d55c7"
      },
      "source": [
        "data['text_1'] = simple_processing(data['text_1'].values)  # используем лемматизацию из unsupervised части"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7227/7227 [00:21<00:00, 343.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T11:13:11.940987Z",
          "start_time": "2018-11-09T11:12:39.094056Z"
        },
        "hidden": true,
        "id": "RZOrhLYNBD0c",
        "outputId": "604e06a6-2b7b-4c62-a4e0-db112e60a108"
      },
      "source": [
        "data['text_2'] = simple_processing(data['text_2'].values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7227/7227 [00:18<00:00, 381.10it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T11:26:22.430450Z",
          "start_time": "2018-11-09T11:26:22.406552Z"
        },
        "hidden": true,
        "id": "_s9dkj6kBD0c"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data[['text_1', 'text_2']], data['class_bin'], \n",
        "                                                    test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T11:26:24.930670Z",
          "start_time": "2018-11-09T11:26:24.599619Z"
        },
        "hidden": true,
        "id": "Pvc0H078BD0c"
      },
      "source": [
        "# строим корпус для обучения doc2vec\n",
        "corpus = pd.DataFrame(pd.concat([X_train['text_1'], X_train['text_2']])).apply(lambda x: ' '.join(x[0]), axis = 1)\n",
        "corpus = corpus.drop_duplicates(keep = 'first') #10840 -> 9263\n",
        "corpus = corpus.apply(lambda x: x.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "pIpQBKdIBD0d"
      },
      "source": [
        "#### Строим эмбеддинги: doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T11:36:35.957891Z",
          "start_time": "2018-11-09T11:36:00.211661Z"
        },
        "hidden": true,
        "id": "qTfnoUlHBD0d",
        "outputId": "150dd165-db88-482c-d4b8-24c11682e182"
      },
      "source": [
        "tagged_data = [TaggedDocument(words=words, tags=[str(i)]) for i, words in enumerate(corpus.values)]\n",
        "max_epochs = 20\n",
        "vec_size = 100\n",
        "alpha = 0.025\n",
        "\n",
        "model = Doc2Vec(size=vec_size,\n",
        "                alpha=alpha, \n",
        "                min_alpha=0.00025,\n",
        "                min_count=1,\n",
        "                dm=0,\n",
        "                dbow_words=0)\n",
        "  \n",
        "model.build_vocab(tagged_data)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print('iteration {0}'.format(epoch))\n",
        "    model.train(tagged_data,\n",
        "                total_examples=model.corpus_count,\n",
        "                epochs=model.iter)\n",
        "    model.alpha -= 0.0002\n",
        "    model.min_alpha = model.alpha\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0\n",
            "iteration 1\n",
            "iteration 2\n",
            "iteration 3\n",
            "iteration 4\n",
            "iteration 5\n",
            "iteration 6\n",
            "iteration 7\n",
            "iteration 8\n",
            "iteration 9\n",
            "iteration 10\n",
            "iteration 11\n",
            "iteration 12\n",
            "iteration 13\n",
            "iteration 14\n",
            "iteration 15\n",
            "iteration 16\n",
            "iteration 17\n",
            "iteration 18\n",
            "iteration 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T11:37:28.235712Z",
          "start_time": "2018-11-09T11:37:28.230957Z"
        },
        "hidden": true,
        "id": "UBZEKRxvBD0d"
      },
      "source": [
        "class Doc2VecVectorizer(object):\n",
        "    def __init__(self, d2v_model):\n",
        "        self.d2v_model = d2v_model\n",
        "        self.dim = d2v_model.vector_size\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([self.d2v_model.infer_vector(text) for text in X])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T11:41:19.574963Z",
          "start_time": "2018-11-09T11:41:17.582874Z"
        },
        "hidden": true,
        "id": "QYYFf_AtBD0d"
      },
      "source": [
        "d2v = Doc2VecVectorizer(model)\n",
        "X_train_text_2 = d2v.transform(X_train.text_2.values)\n",
        "X_test_text_2 = d2v.transform(X_test.text_2.values)\n",
        "X_train_text_1 = d2v.transform(X_train.text_1.values)\n",
        "X_test_text_1 = d2v.transform(X_test.text_1.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T11:41:39.212240Z",
          "start_time": "2018-11-09T11:41:39.168896Z"
        },
        "hidden": true,
        "id": "E8RU8vR4BD0d"
      },
      "source": [
        "X_train = [np.concatenate((X_train_text_1[i], X_train_text_2[i])) for i in range(len(X_train_text_1))]\n",
        "X_test = [np.concatenate((X_test_text_1[i], X_test_text_2[i])) for i in range(len(X_test_text_1))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "TWMHqz6LBD0e"
      },
      "source": [
        "#### Doc2Vec + LogReg, SVM, RandomForest, GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T13:36:34.352971Z",
          "start_time": "2018-11-09T13:18:51.494187Z"
        },
        "hidden": true,
        "scrolled": true,
        "id": "mK7wjA3oBD0e",
        "outputId": "e14bff27-c100-4c74-eea4-c8977f121f39"
      },
      "source": [
        "pipe_logreg = LogisticRegression(random_state=666, n_jobs = -1)\n",
        "\n",
        "pipe_svm = SVC(random_state=666)\n",
        "\n",
        "pipe_forest = RandomForestClassifier(random_state=666)\n",
        "\n",
        "pipe_boost = GradientBoostingClassifier(random_state=666)\n",
        "\n",
        "grid_params_logreg = [{'penalty': ('l1', 'l2'),\n",
        "                   'C': [1.0, 0.5, 0.1]}] \n",
        "\n",
        "grid_params_svm = [{'kernel': ('linear', 'poly', 'rbf'),\n",
        "                   'C': [1.0, 0.5, 0.1],\n",
        "                   'degree': [3, 5]}] \n",
        "\n",
        "grid_params_forest = [{'n_estimators' : [10, 20], \n",
        "                   'criterion': ('gini', 'entropy'),\n",
        "                   'min_samples_leaf': [50, 100, 200],\n",
        "                   'max_depth': [50, 100],\n",
        "                   'min_samples_split': [50, 100]}]\n",
        "\n",
        "grid_params_boost = [{'loss': ('deviance', 'exponential'), \n",
        "                    'min_samples_leaf': [50, 100], \n",
        "                    'subsample' : [0.5, 0.7, 1.0], \n",
        "                    'n_estimators' : [100, 200]}]\n",
        "\n",
        "\n",
        "models = {'logreg' : [pipe_logreg, grid_params_logreg],\n",
        "          'svm' : [pipe_svm, grid_params_svm], \n",
        "          'forest': [pipe_forest, grid_params_forest],\n",
        "          'boost' : [pipe_boost, grid_params_boost]}\n",
        "\n",
        "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
        "          'f1_score_macro' : make_scorer(f1_score, average = 'macro')}\n",
        "\n",
        "\n",
        "best_acc = 0.0\n",
        "best_f1 = 0.0\n",
        "best_clf_acc = ''\n",
        "best_clf_f1 = ''\n",
        "\n",
        "\n",
        "for clf in models.keys():\n",
        "    print('\\nEstimator: %s' % models[clf])\n",
        "    grid_cv = GridSearchCV(estimator = models[clf][0], param_grid = models[clf][1][0], n_jobs = -1, \n",
        "                           scoring = scoring, refit = 'f1_score_macro')\n",
        "    grid_cv.fit(X_train, y_train)\n",
        "    print('Best params: %s' % grid_cv.best_params_)\n",
        "    print('Best training accuracy: %.3f' % grid_cv.best_score_)\n",
        "    y_pred = grid_cv.predict(X_test)\n",
        "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
        "    print('Test set f1_score (macro) for best params: %.3f ' % f1_score(y_test, y_pred, average='macro'))\n",
        "    results.add(accuracy_score(y_test, y_pred), clf, 'acc', 'Doc2Vec')\n",
        "    results.add(f1_score(y_test, y_pred, average='macro'), clf, 'f1', 'Doc2Vec')\n",
        "    if accuracy_score(y_test, y_pred) > best_acc:\n",
        "        best_acc = accuracy_score(y_test, y_pred)\n",
        "        best_clf_acc = str(grid_cv.best_estimator_)\n",
        "        \n",
        "    if f1_score(y_test, y_pred, average='macro') > best_f1:\n",
        "        best_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "        best_clf_f1 = str(grid_cv.best_estimator_)\n",
        "        \n",
        "print('\\nClassifier with best test set accuracy: %s' % best_clf_acc)\n",
        "print('\\nClassifier with best test set f1 macro score: %s' % best_clf_f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Estimator: [LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
            "          penalty='l2', random_state=666, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False), [{'penalty': ('l1', 'l2'), 'C': [1.0, 0.5, 0.1]}]]\n",
            "Best params: {'C': 1.0, 'penalty': 'l2'}\n",
            "Best training accuracy: 0.599\n",
            "Test set accuracy score for best params: 0.664 \n",
            "Test set f1_score (macro) for best params: 0.610 \n",
            "\n",
            "Estimator: [SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
            "  max_iter=-1, probability=False, random_state=666, shrinking=True,\n",
            "  tol=0.001, verbose=False), [{'kernel': ('linear', 'poly', 'rbf'), 'C': [1.0, 0.5, 0.1], 'degree': [3, 5]}]]\n",
            "Best params: {'C': 1.0, 'degree': 3, 'kernel': 'linear'}\n",
            "Best training accuracy: 0.575\n",
            "Test set accuracy score for best params: 0.678 \n",
            "Test set f1_score (macro) for best params: 0.581 \n",
            "\n",
            "Estimator: [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
            "            oob_score=False, random_state=666, verbose=0, warm_start=False), [{'n_estimators': [10, 20], 'criterion': ('gini', 'entropy'), 'min_samples_leaf': [50, 100, 200], 'max_depth': [50, 100], 'min_samples_split': [50, 100]}]]\n",
            "Best params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_leaf': 50, 'min_samples_split': 50, 'n_estimators': 10}\n",
            "Best training accuracy: 0.513\n",
            "Test set accuracy score for best params: 0.681 \n",
            "Test set f1_score (macro) for best params: 0.548 \n",
            "\n",
            "Estimator: [GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=1, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "              presort='auto', random_state=666, subsample=1.0, verbose=0,\n",
            "              warm_start=False), [{'loss': ('deviance', 'exponential'), 'min_samples_leaf': [50, 100], 'subsample': [0.5, 0.7, 1.0], 'n_estimators': [100, 200]}]]\n",
            "Best params: {'loss': 'deviance', 'min_samples_leaf': 100, 'n_estimators': 200, 'subsample': 0.7}\n",
            "Best training accuracy: 0.714\n",
            "Test set accuracy score for best params: 0.755 \n",
            "Test set f1_score (macro) for best params: 0.720 \n",
            "\n",
            "Classifier with best test set accuracy: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=100, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
            "              presort='auto', random_state=666, subsample=0.7, verbose=0,\n",
            "              warm_start=False)\n",
            "\n",
            "Classifier with best test set f1 macro score: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=100, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
            "              presort='auto', random_state=666, subsample=0.7, verbose=0,\n",
            "              warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d7SdFsoBD0e"
      },
      "source": [
        "### FastText"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi_DFaFFBD0e"
      },
      "source": [
        "#### Усредненный FastText "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlTooHlkBD0e"
      },
      "source": [
        "model = FastText.load_fasttext_format('cc.ru.300.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "UPBPLUx-BD0f",
        "outputId": "da3ac447-6757-440a-df64-38d4ac691ae3"
      },
      "source": [
        "data = pd.read_csv('data_hw2.csv')\n",
        "data['class_bin'] = data['class'].apply(lambda x: 1 if x != -1 else -1).values\n",
        "data['text_1'] = simple_processing(data['text_1'])\n",
        "data['text_2'] = simple_processing(data['text_2'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7227/7227 [00:25<00:00, 287.58it/s]\n",
            "100%|██████████| 7227/7227 [00:22<00:00, 321.42it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73S_9biwBD0f"
      },
      "source": [
        "data['text_1_con'] = [' '.join(text) for text in data['text_1']]\n",
        "data['text_2_con'] = [' '.join(text) for text in data['text_2']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0iR2CjiBD0f"
      },
      "source": [
        "corpus = pd.concat([data['text_1_con'], data['text_2_con']]).unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9NHyJEpBD0f"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data[['text_1', 'text_2']], data['class_bin'], test_size = 0.25,\n",
        "                                                    random_state = 666)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL9WiITWBD0f"
      },
      "source": [
        "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytj5vNOPBD0f"
      },
      "source": [
        "mean_emb = MeanEmbeddingVectorizer(w2v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BFwSZzaBD0g"
      },
      "source": [
        "X_train_text_2 = mean_emb.transform(X_train.text_2.values)\n",
        "X_test_text_2 = mean_emb.transform(X_test.text_2.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwCT-wNDBD0g"
      },
      "source": [
        "X_train_text_1 = mean_emb.transform(X_train.text_1.values)\n",
        "X_test_text_1 = mean_emb.transform(X_test.text_1.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErGw4MMBBD0g"
      },
      "source": [
        "X_train = [np.concatenate((X_train_text_1[i], X_train_text_2[i])) for i in range(len(X_train_text_1))]\n",
        "X_test = [np.concatenate((X_test_text_1[i], X_test_text_2[i])) for i in range(len(X_test_text_1))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_Dr1jyMBD0g"
      },
      "source": [
        "#### FastText + LogReg, SVM, RandomForest, GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdQdXb7SBD0g",
        "outputId": "9d3bcbe7-f3b2-4e96-922b-7e0108ba2bcf"
      },
      "source": [
        "pipe_logreg = LogisticRegression(random_state=666, n_jobs = -1)\n",
        "\n",
        "pipe_svm = SVC(random_state=666)\n",
        "\n",
        "pipe_forest = RandomForestClassifier(random_state=666)\n",
        "\n",
        "pipe_boost = GradientBoostingClassifier(random_state=666)\n",
        "\n",
        "grid_params_logreg = [{'penalty': ('l1', 'l2'),\n",
        "                   'C': [1.0, 0.5, 0.1]}] \n",
        "\n",
        "grid_params_svm = [{'kernel': ('linear', 'poly', 'rbf'),\n",
        "                   'C': [1.0, 0.5, 0.1],\n",
        "                   'degree': [3, 5]}] \n",
        "\n",
        "grid_params_forest = [{'n_estimators' : [10, 20], \n",
        "                   'criterion': ('gini', 'entropy'),\n",
        "                   'min_samples_leaf': [50, 100, 200],\n",
        "                   'max_depth': [50, 100],\n",
        "                   'min_samples_split': [50, 100]}]\n",
        "\n",
        "grid_params_boost = [{'loss': ('deviance', 'exponential'), \n",
        "                    'min_samples_leaf': [50, 100], \n",
        "                    'subsample' : [0.5, 0.7, 1.0], \n",
        "                    'n_estimators' : [100, 200]}]\n",
        "\n",
        "\n",
        "models = {'logreg' : [pipe_logreg, grid_params_logreg],\n",
        "          'svm' : [pipe_svm, grid_params_svm], \n",
        "          'forest': [pipe_forest, grid_params_forest],\n",
        "          'boost' : [pipe_boost, grid_params_boost]}\n",
        "\n",
        "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
        "          'f1_score_macro' : make_scorer(f1_score, average = 'macro')}\n",
        "\n",
        "\n",
        "best_acc = 0.0\n",
        "best_f1 = 0.0\n",
        "best_clf_acc = ''\n",
        "best_clf_f1 = ''\n",
        "\n",
        "\n",
        "for clf in models.keys():\n",
        "    print('\\nEstimator: %s' % models[clf])\n",
        "    grid_cv = GridSearchCV(estimator = models[clf][0], param_grid = models[clf][1][0], n_jobs = -1, \n",
        "                           scoring = scoring, refit = 'f1_score_macro')\n",
        "    grid_cv.fit(X_train, y_train)\n",
        "    print('Best params: %s' % grid_cv.best_params_)\n",
        "    print('Best training accuracy: %.3f' % grid_cv.best_score_)\n",
        "    y_pred = grid_cv.predict(X_test)\n",
        "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
        "    print('Test set f1_score (macro) for best params: %.3f ' % f1_score(y_test, y_pred, average='macro'))\n",
        "    results.add(accuracy_score(y_test, y_pred), clf, 'acc', 'Fasttext')\n",
        "    results.add(f1_score(y_test, y_pred, average='macro'), clf, 'f1', 'Fasttext')\n",
        "    \n",
        "    if accuracy_score(y_test, y_pred) > best_acc:\n",
        "        best_acc = accuracy_score(y_test, y_pred)\n",
        "        best_clf_acc = str(grid_cv.best_estimator_)\n",
        "        \n",
        "    if f1_score(y_test, y_pred, average='macro') > best_f1:\n",
        "        best_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "        best_clf_f1 = str(grid_cv.best_estimator_)\n",
        "        \n",
        "print('\\nClassifier with best test set accuracy: %s' % best_clf_acc)\n",
        "print('\\nClassifier with best test set f1 macro score: %s' % best_clf_f1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Estimator: [LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
            "          penalty='l2', random_state=666, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False), [{'penalty': ('l1', 'l2'), 'C': [1.0, 0.5, 0.1]}]]\n",
            "Best params: {'C': 1.0, 'penalty': 'l1'}\n",
            "Best training accuracy: 0.569\n",
            "Test set accuracy score for best params: 0.681 \n",
            "Test set f1_score (macro) for best params: 0.573 \n",
            "\n",
            "Estimator: [SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
            "  max_iter=-1, probability=False, random_state=666, shrinking=True,\n",
            "  tol=0.001, verbose=False), [{'kernel': ('linear', 'poly', 'rbf'), 'C': [1.0, 0.5, 0.1], 'degree': [3, 5]}]]\n",
            "Best params: {'C': 1.0, 'degree': 3, 'kernel': 'linear'}\n",
            "Best training accuracy: 0.512\n",
            "Test set accuracy score for best params: 0.677 \n",
            "Test set f1_score (macro) for best params: 0.515 \n",
            "\n",
            "Estimator: [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
            "            oob_score=False, random_state=666, verbose=0, warm_start=False), [{'n_estimators': [10, 20], 'criterion': ('gini', 'entropy'), 'min_samples_leaf': [50, 100, 200], 'max_depth': [50, 100], 'min_samples_split': [50, 100]}]]\n",
            "Best params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 50, 'min_samples_split': 50, 'n_estimators': 10}\n",
            "Best training accuracy: 0.518\n",
            "Test set accuracy score for best params: 0.678 \n",
            "Test set f1_score (macro) for best params: 0.523 \n",
            "\n",
            "Estimator: [GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=1, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "              presort='auto', random_state=666, subsample=1.0, verbose=0,\n",
            "              warm_start=False), [{'loss': ('deviance', 'exponential'), 'min_samples_leaf': [50, 100], 'subsample': [0.5, 0.7, 1.0], 'n_estimators': [100, 200]}]]\n",
            "Best params: {'loss': 'deviance', 'min_samples_leaf': 100, 'n_estimators': 200, 'subsample': 1.0}\n",
            "Best training accuracy: 0.717\n",
            "Test set accuracy score for best params: 0.755 \n",
            "Test set f1_score (macro) for best params: 0.702 \n",
            "\n",
            "Classifier with best test set accuracy: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=100, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
            "              presort='auto', random_state=666, subsample=1.0, verbose=0,\n",
            "              warm_start=False)\n",
            "\n",
            "Classifier with best test set f1 macro score: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=100, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
            "              presort='auto', random_state=666, subsample=1.0, verbose=0,\n",
            "              warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3gPuqCyBD0g"
      },
      "source": [
        "#### Weighted FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__idJpx3BD0h",
        "outputId": "c0020ab2-936d-46dd-cede-cce35875e83d"
      },
      "source": [
        "data = pd.read_csv('data_hw2.csv')\n",
        "data['class_bin'] = data['class'].apply(lambda x: 1 if x != -1 else -1).values\n",
        "data['text_1'] = simple_processing(data['text_1'])\n",
        "data['text_2'] = simple_processing(data['text_2'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7227/7227 [00:25<00:00, 286.87it/s]\n",
            "100%|██████████| 7227/7227 [00:22<00:00, 314.73it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBVzREhJBD0h"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data[['text_1', 'text_2']], data['class_bin'], test_size = 0.25,\n",
        "                                                    random_state = 666)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iHOmbWlBD0h",
        "outputId": "71c11ae2-d121-4fba-eb5a-af0cb6ce8596"
      },
      "source": [
        "tf_emb = TfidfEmbeddingVectorizer(w2v)\n",
        "tf_emb.fit(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.TfidfEmbeddingVectorizer at 0x7fb155544198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BhP6NmoBD0h"
      },
      "source": [
        "X_train_text_1, X_test_text_1 = tf_emb.transform(X_train.text_1.values), tf_emb.transform(X_test.text_1.values)\n",
        "X_train_text_2, X_test_text_2  = tf_emb.transform(X_train.text_2.values), tf_emb.transform(X_test.text_2.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVfaHhmxBD0i"
      },
      "source": [
        "X_train = [np.concatenate((X_train_text_1[i], X_train_text_2[i])) for i in range(len(X_train_text_1))]\n",
        "X_test = [np.concatenate((X_test_text_1[i], X_test_text_2[i])) for i in range(len(X_test_text_1))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Je7YoiRBD0i"
      },
      "source": [
        "#### Weightned FastText + LogReg, SVM, RandomForest, GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZEd9YA8BD0i",
        "outputId": "d224d3d7-05c3-455a-90f8-b7b284c20be5"
      },
      "source": [
        "pipe_logreg = LogisticRegression(random_state=666, n_jobs = -1)\n",
        "\n",
        "pipe_svm = SVC(random_state=666)\n",
        "\n",
        "pipe_forest = RandomForestClassifier(random_state=666)\n",
        "\n",
        "pipe_boost = GradientBoostingClassifier(random_state=666)\n",
        "\n",
        "grid_params_logreg = [{'penalty': ('l1', 'l2'),\n",
        "                   'C': [1.0, 0.5, 0.1]}] \n",
        "\n",
        "grid_params_svm = [{'kernel': ('linear', 'poly', 'rbf'),\n",
        "                   'C': [1.0, 0.5, 0.1],\n",
        "                   'degree': [3, 5]}] \n",
        "\n",
        "grid_params_forest = [{'n_estimators' : [10, 20], \n",
        "                   'criterion': ('gini', 'entropy'),\n",
        "                   'min_samples_leaf': [50, 100, 200],\n",
        "                   'max_depth': [50, 100],\n",
        "                   'min_samples_split': [50, 100]}]\n",
        "\n",
        "grid_params_boost = [{'loss': ('deviance', 'exponential'), \n",
        "                    'min_samples_leaf': [50, 100], \n",
        "                    'subsample' : [0.5, 0.7, 1.0], \n",
        "                    'n_estimators' : [100, 200]}]\n",
        "\n",
        "\n",
        "models = {'logreg' : [pipe_logreg, grid_params_logreg],\n",
        "          'svm' : [pipe_svm, grid_params_svm], \n",
        "          'forest': [pipe_forest, grid_params_forest],\n",
        "          'boost' : [pipe_boost, grid_params_boost]}\n",
        "\n",
        "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
        "          'f1_score_macro' : make_scorer(f1_score, average = 'macro')}\n",
        "\n",
        "\n",
        "best_acc = 0.0\n",
        "best_f1 = 0.0\n",
        "best_clf_acc = ''\n",
        "best_clf_f1 = ''\n",
        "\n",
        "\n",
        "for clf in models.keys():\n",
        "    print('\\nEstimator: %s' % models[clf])\n",
        "    grid_cv = GridSearchCV(estimator = models[clf][0], param_grid = models[clf][1][0], n_jobs = -1, \n",
        "                           scoring = scoring, refit = 'f1_score_macro')\n",
        "    grid_cv.fit(X_train, y_train)\n",
        "    print('Best params: %s' % grid_cv.best_paramеs_)\n",
        "    print('Best training accuracy: %.3f' % grid_cv.best_score_)\n",
        "    y_pred = grid_cv.predict(X_test)\n",
        "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
        "    print('Test set f1_score (macro) for best params: %.3f ' % f1_score(y_test, y_pred, average='macro'))\n",
        "    results.add(accuracy_score(y_test, y_pred), clf, 'acc', 'Weighted_Fasttext')\n",
        "    results.add(f1_score(y_test, y_pred, average='macro'), clf, 'f1', 'Weighted_Fasttext')\n",
        "    if accuracy_score(y_test, y_pred) > best_acc:\n",
        "        best_acc = accuracy_score(y_test, y_pred)\n",
        "        best_clf_acc = str(grid_cv.best_estimator_)\n",
        "        \n",
        "    if f1_score(y_test, y_pred, average='macro') > best_f1:\n",
        "        best_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "        best_clf_f1 = str(grid_cv.best_estimator_)\n",
        "        \n",
        "print('\\nClassifier with best test set accuracy: %s' % best_clf_acc)\n",
        "print('\\nClassifier with best test set f1 macro score: %s' % best_clf_f1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Estimator: [LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
            "          penalty='l2', random_state=666, solver='liblinear', tol=0.0001,\n",
            "          verbose=0, warm_start=False), [{'penalty': ('l1', 'l2'), 'C': [1.0, 0.5, 0.1]}]]\n",
            "Best params: {'C': 1.0, 'penalty': 'l1'}\n",
            "Best training accuracy: 0.631\n",
            "Test set accuracy score for best params: 0.668 \n",
            "Test set f1_score (macro) for best params: 0.608 \n",
            "\n",
            "Estimator: [SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
            "  max_iter=-1, probability=False, random_state=666, shrinking=True,\n",
            "  tol=0.001, verbose=False), [{'kernel': ('linear', 'poly', 'rbf'), 'C': [1.0, 0.5, 0.1], 'degree': [3, 5]}]]\n",
            "Best params: {'C': 0.5, 'degree': 3, 'kernel': 'linear'}\n",
            "Best training accuracy: 0.627\n",
            "Test set accuracy score for best params: 0.670 \n",
            "Test set f1_score (macro) for best params: 0.610 \n",
            "\n",
            "Estimator: [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
            "            oob_score=False, random_state=666, verbose=0, warm_start=False), [{'n_estimators': [10, 20], 'criterion': ('gini', 'entropy'), 'min_samples_leaf': [50, 100, 200], 'max_depth': [50, 100], 'min_samples_split': [50, 100]}]]\n",
            "Best params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_leaf': 50, 'min_samples_split': 50, 'n_estimators': 10}\n",
            "Best training accuracy: 0.528\n",
            "Test set accuracy score for best params: 0.678 \n",
            "Test set f1_score (macro) for best params: 0.524 \n",
            "\n",
            "Estimator: [GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=1, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "              presort='auto', random_state=666, subsample=1.0, verbose=0,\n",
            "              warm_start=False), [{'loss': ('deviance', 'exponential'), 'min_samples_leaf': [50, 100], 'subsample': [0.5, 0.7, 1.0], 'n_estimators': [100, 200]}]]\n",
            "Best params: {'loss': 'deviance', 'min_samples_leaf': 100, 'n_estimators': 200, 'subsample': 1.0}\n",
            "Best training accuracy: 0.719\n",
            "Test set accuracy score for best params: 0.750 \n",
            "Test set f1_score (macro) for best params: 0.694 \n",
            "\n",
            "Classifier with best test set accuracy: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=100, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
            "              presort='auto', random_state=666, subsample=1.0, verbose=0,\n",
            "              warm_start=False)\n",
            "\n",
            "Classifier with best test set f1 macro score: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "              max_features=None, max_leaf_nodes=None,\n",
            "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "              min_samples_leaf=100, min_samples_split=2,\n",
            "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
            "              presort='auto', random_state=666, subsample=1.0, verbose=0,\n",
            "              warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtltlFCNBD0i"
      },
      "source": [
        "### Результаты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-09T13:36:49.579448Z",
          "start_time": "2018-11-09T13:36:49.560222Z"
        },
        "id": "cVpUSZENBD0i",
        "outputId": "093a38b0-b554-453b-9959-112f9b3f1407"
      },
      "source": [
        "results.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logreg_acc</th>\n",
              "      <th>logreg_f1</th>\n",
              "      <th>svm_acc</th>\n",
              "      <th>svm_f1</th>\n",
              "      <th>boost_acc</th>\n",
              "      <th>boost_f1</th>\n",
              "      <th>forest_acc</th>\n",
              "      <th>forest_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Word2Vec</th>\n",
              "      <td>0.679026</td>\n",
              "      <td>0.56704</td>\n",
              "      <td>0.679579</td>\n",
              "      <td>0.517176</td>\n",
              "      <td>0.727726</td>\n",
              "      <td>0.667509</td>\n",
              "      <td>0.666851</td>\n",
              "      <td>0.489535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weighted_Word2Vec</th>\n",
              "      <td>0.643608</td>\n",
              "      <td>0.579619</td>\n",
              "      <td>0.653016</td>\n",
              "      <td>0.580335</td>\n",
              "      <td>0.727726</td>\n",
              "      <td>0.667509</td>\n",
              "      <td>0.666851</td>\n",
              "      <td>0.489535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc2Vec</th>\n",
              "      <td>0.663531</td>\n",
              "      <td>0.609715</td>\n",
              "      <td>0.678473</td>\n",
              "      <td>0.580869</td>\n",
              "      <td>0.755396</td>\n",
              "      <td>0.720436</td>\n",
              "      <td>0.68124</td>\n",
              "      <td>0.548032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fasttext</th>\n",
              "      <td>0.68124</td>\n",
              "      <td>0.572611</td>\n",
              "      <td>0.677366</td>\n",
              "      <td>0.514778</td>\n",
              "      <td>0.754842</td>\n",
              "      <td>0.702492</td>\n",
              "      <td>0.678473</td>\n",
              "      <td>0.522837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weighted_Fasttext</th>\n",
              "      <td>0.667958</td>\n",
              "      <td>0.607941</td>\n",
              "      <td>0.669618</td>\n",
              "      <td>0.609702</td>\n",
              "      <td>0.749862</td>\n",
              "      <td>0.693834</td>\n",
              "      <td>0.677919</td>\n",
              "      <td>0.524241</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  logreg_acc logreg_f1   svm_acc    svm_f1 boost_acc  \\\n",
              "Word2Vec            0.679026   0.56704  0.679579  0.517176  0.727726   \n",
              "Weighted_Word2Vec   0.643608  0.579619  0.653016  0.580335  0.727726   \n",
              "Doc2Vec             0.663531  0.609715  0.678473  0.580869  0.755396   \n",
              "Fasttext             0.68124  0.572611  0.677366  0.514778  0.754842   \n",
              "Weighted_Fasttext   0.667958  0.607941  0.669618  0.609702  0.749862   \n",
              "\n",
              "                   boost_f1 forest_acc forest_f1  \n",
              "Word2Vec           0.667509   0.666851  0.489535  \n",
              "Weighted_Word2Vec  0.667509   0.666851  0.489535  \n",
              "Doc2Vec            0.720436    0.68124  0.548032  \n",
              "Fasttext           0.702492   0.678473  0.522837  \n",
              "Weighted_Fasttext  0.693834   0.677919  0.524241  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "B3pF-LE_BD0i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}